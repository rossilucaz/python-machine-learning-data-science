{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação dos Algoritimos\n",
    "- Naïve Bayes: 93.80\n",
    "- Árvore de Decisão: 98.20\n",
    "- Regras: 97.40\n",
    "- Regressão Logística: 94.60\n",
    "- SVM: 98.80\n",
    "- Redes Neurais: 99.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning dos Parâmetros com GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credit.pkl', 'rb') as f:\n",
    "    x_credit_treinamento, y_credit_treinamento, x_credit_teste, y_credit_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_credit_treinamento.shape, y_credit_treinamento.shape, x_credit_teste.shape, y_credit_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_credit = np.concatenate((x_credit_treinamento, x_credit_teste), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_credit = np.concatenate((y_credit_treinamento,y_credit_teste), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {'criterion' : ['gini', 'entropy'], # métodos para medir a impureza de um nó\n",
    "              'splitter': ['best', 'random'], #  escolher a divisão em cada nó\n",
    "              'min_samples_split': [2, 5, 10], # número mínimo de amostras necessárias para dividir um nó\n",
    "              'min_samples_leaf': [1, 5, 10] } # número mínimo de amostras necessário para ser considerado como uma folha (nó terminal) da árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=parametros)\n",
    "grid_search.fit(x_credit, y_credit)\n",
    "melhores_parametros = grid_search.best_params_\n",
    "melhores_resultados = grid_search.best_score_\n",
    "print(melhores_parametros)\n",
    "print(melhores_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {'criterion' : ['gini', 'entropy'], # métodos para medir a impureza de um nó\n",
    "              'n_estimators': [10, 40, 100, 500], # número de árvores na floresta\n",
    "              'min_samples_split': [2, 5, 10], # número mínimo de amostras necessárias para dividir um nó\n",
    "              'min_samples_leaf': [1, 5, 10] } # número mínimo de amostras necessário para ser considerado como uma folha (nó terminal) da árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parametros)\n",
    "grid_search.fit(x_credit, y_credit)\n",
    "melhores_parametros = grid_search.best_params_\n",
    "melhores_resultados = grid_search.best_score_\n",
    "print(melhores_parametros)\n",
    "print(melhores_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {'n_neighbors' : [3, 5, 10, 20], #  número de vizinhos mais próximos considerados ao fazer uma previsão \n",
    "              'p': [1,2]} # distância a ser utilizada para calcular a proximidade entre pontos. Quando p=1 Manhattan, p=2 Euclidiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=parametros)\n",
    "grid_search.fit(x_credit, y_credit)\n",
    "melhores_parametros = grid_search.best_params_\n",
    "melhores_resultados = grid_search.best_score_\n",
    "print(melhores_parametros)\n",
    "print(melhores_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {'tol' : [0.0001, 0.00001, 0.000001], #  tolerância para o critério de parada\n",
    "              'C' : [1.0, 1.5, 2.0], # força da regularização no modelo, menores de C indicam uma regularização mais forte, o que pode ajudar a evitar overfitting, enquanto valores maiores indicam uma regularização mais fraca.\n",
    "              'solver' : ['lbfgs', 'sag', 'saga']} # especifica o algoritmo a ser usado no problema de otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=parametros)\n",
    "grid_search.fit(x_credit, y_credit)\n",
    "melhores_parametros = grid_search.best_params_\n",
    "melhores_resultados = grid_search.best_score_\n",
    "print(melhores_parametros)\n",
    "print(melhores_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {'tol' : [0.001, 0.0001, 0.00001], #  tolerância para o critério de parada\n",
    "              'C' : [1.0, 1.5, 2.0], #  controla a força da regularização no modelo SVM\n",
    "              'kernel' : ['rbf', 'linear', 'poly', 'sigmoid']} # especifica o tipo de função de kernel a ser usado no modelo SVM, o kernel determina o mapeamento das características do espaço original para um espaço de características de maior dimensão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=SVC(), param_grid=parametros)\n",
    "grid_search.fit(x_credit, y_credit)\n",
    "melhores_parametros = grid_search.best_params_\n",
    "melhores_resultados = grid_search.best_score_\n",
    "print(melhores_parametros)\n",
    "print(melhores_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {'activation' :  ['relu', 'logistic', 'tahn'], # define a função de ativação a ser usada nas camadas ocultas da rede neural\n",
    "              'solver' : ['adam', 'sgd'], # especifica o algoritmo de otimização a ser usado durante o treinamento da rede neural\n",
    "              'batch_size' : [10, 56]} # define o número de amostras de dados que serão usadas em cada iteração durante o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=MLPClassifier(), param_grid=parametros)\n",
    "grid_search.fit(x_credit, y_credit)\n",
    "melhores_parametros = grid_search.best_params_\n",
    "melhores_resultados = grid_search.best_score_\n",
    "print(melhores_parametros)\n",
    "print(melhores_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import cross_val_predict, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "resultados_knn = []\n",
    "resultados_svm = []\n",
    "resultados_arvore = []\n",
    "resultados_logistica = []\n",
    "resultados_rede_neural = []\n",
    "resultados_random_forest = []\n",
    "\n",
    "for i in range(30): # é utilizado 30 testes geralmente\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    \n",
    "    arvore = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=1, min_samples_split=5, splitter='best')\n",
    "    scores = cross_val_score(arvore, x_credit, y_credit, cv = kfold)\n",
    "    #print(scores) \n",
    "    #print(scores.mean())\n",
    "    resultados_arvore.append(scores.mean())\n",
    "    \n",
    "    random_forest = RandomForestClassifier(criterion='entropy', min_samples_leaf=1, min_samples_split=5, n_estimators=10)\n",
    "    score = cross_val_score(random_forest, x_credit, y_credit, cv=kfold)\n",
    "    resultados_random_forest.append(score.mean())\n",
    "    \n",
    "    knn = KNeighborsClassifier()\n",
    "    scores = cross_val_score(knn, x_credit, y_credit, cv = kfold)\n",
    "    resultados_knn.append(scores.mean())\n",
    "    \n",
    "    logistica = LogisticRegression(C=1.0, solver='lbfgs', tol=0.0001)\n",
    "    scores = cross_val_score(logistica, x_credit, y_credit, cv=kfold)\n",
    "    resultados_logistica.append(scores.mean())\n",
    "    \n",
    "    svm = SVC(kernel='rbf', C=2.0)\n",
    "    scores = cross_val_score(svm, x_credit, y_credit, cv=kfold)\n",
    "    resultados_svm.append(scores.mean())\n",
    "    \n",
    "    rede_neural = MLPClassifier(activation='relu', batch_size=56, solver='adam')\n",
    "    scores = cross_val_score(rede_neural, x_credit, y_credit, cv=kfold)\n",
    "    resultados_rede_neural.append(scores.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_knn, resultados_svm, resultados_arvore, resultados_logistica, resultados_rede_neural, resultados_random_forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = pd.DataFrame({'Arvore': resultados_arvore,\n",
    "                          'Random Forest' : resultados_random_forest,\n",
    "                          'KNN' : resultados_knn,\n",
    "                          'Logistica' : resultados_logistica,\n",
    "                          'SVM' : resultados_svm,\n",
    "                          'Rede Neural' : resultados_rede_neural})\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(resultados.std() / resultados.mean()) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste de Normalidade nos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 # confiança do teste é de 95 default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro(resultados_arvore), shapiro(resultados_random_forest), shapiro(resultados_knn), shapiro(resultados_logistica), shapiro(resultados_svm), shapiro(resultados_rede_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(resultados_arvore, kind='kde' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(resultados_random_forest, kind='kde' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(resultados_knn, kind='kde' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(resultados_logistica, kind='kde' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(resultados_rede_neural, kind='kde') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste de Hipótese com ANOVA e Tukey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p = f_oneway(resultados_arvore, resultados_random_forest, resultados_logistica, resultados_svm, resultados_knn, resultados_rede_neural)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "if p <= alpha:\n",
    "    print('Hipótese nula rejeitada. Os dados são diferentes')\n",
    "else:\n",
    "    print('Hipótese alternativa rejeitada. Os resultados são iguais')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_algoritimos = {'accurancy' : np.concatenate([resultados_arvore, resultados_random_forest, resultados_logistica, resultados_knn, resultados_svm, resultados_rede_neural]),\n",
    "                          'algoritimos' : ['arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore', 'arvore',\n",
    "                          'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', 'random_forest', \n",
    "                          'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica', 'logistica',\n",
    "                          'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn','knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn', 'knn',\n",
    "                          'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv', 'smv',\n",
    "                          'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural', 'rede_neural']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(resultados_algoritimos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from statsmodels.stats.multicomp import MultiComparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compara_algoritimos =  MultiComparison(df_resultados['accurancy'], df_resultados['algoritimos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_estatistico = compara_algoritimos.tukeyhsd()\n",
    "print(teste_estatistico) # se reject é true quer dizer que os algoritimos são diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_estatistico.plot_simultaneous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando um Classificador já treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credit.pkl', 'rb') as f:\n",
    "    x_credit_treinamento, y_credit_treinamento, x_credit_teste, y_credit_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_credit = np.concatenate((x_credit_treinamento, x_credit_teste), axis=0)\n",
    "y_credit = np.concatenate((y_credit_treinamento, y_credit_teste), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_credit.shape, y_credit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_rede_neural = MLPClassifier(activation='relu', batch_size=56, solver='adam')\n",
    "classificador_rede_neural.fit(x_credit, y_credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_arvore = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=1,  min_samples_split=5, splitter='best')\n",
    "classificador_arvore.fit(x_credit, y_credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_svm = SVC(C=2.0, kernel='rbf')\n",
    "classificador_svm.fit(x_credit, y_credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classificador_rede_neural, open('rede_neural_finalizado.sav', 'wb'))\n",
    "pickle.dump(classificador_arvore, open('arvore_finalizada.sav', 'wb'))\n",
    "pickle.dump(classificador_svm, open('svm_finalizado.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar um Classificador já Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede_neural = pickle.load(open('rede_neural_finalizado.sav', 'rb'))\n",
    "arvore = pickle.load(open('arvore_finalizada.sav', 'rb'))\n",
    "smv = pickle.load(open('svm_finalizado.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo_registro = x_credit[0]\n",
    "novo_registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo_registro = novo_registro.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo_registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede_neural.predict(novo_registro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore.predict(novo_registro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.predict(novo_registro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinação e Rejeição de Classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinação de Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo_registros = x_credit[0] # 1999 nao paga emrpestimo\n",
    "novo_registros.shape\n",
    "novo_registro = novo_registro.reshape(1, -1)\n",
    "novo_registro, novo_registro.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta_rede_neural = rede_neural.predict(novo_registro)\n",
    "resposta_arvore = arvore.predict(novo_registro)\n",
    "resposta_svm = svm.predict(novo_registro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paga = 0\n",
    "nao_paga = 0\n",
    "\n",
    "if resposta_rede_neural[0] == 1:\n",
    "    nao_paga +=1\n",
    "else:\n",
    "    paga += 1\n",
    "\n",
    "if resposta_arvore[0] == 1:\n",
    "    nao_paga += 1\n",
    "else: \n",
    "    paga += 2\n",
    "    \n",
    "if resposta_svm[0] == 1:\n",
    "    nao_paga += 1\n",
    "else:\n",
    "    paga += 1\n",
    "    \n",
    "if paga == 1:\n",
    "    print('Cliente não pagará o empéstimo')\n",
    "elif paga == nao_paga:\n",
    "    print('Empate')\n",
    "else:\n",
    "    print('Não paga')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
